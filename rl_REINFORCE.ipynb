{
 "cells": [
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-25T13:00:08.124341Z",
     "start_time": "2025-08-25T13:00:02.657373Z"
    }
   },
   "source": [
    "import math\n",
    "import random\n",
    "\n",
    "import gymnasium as gym\n",
    "import numpy as np\n",
    "from mad_pod_racing import MapPodRacing\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "from torch.distributions import Normal, Categorical\n",
    "from IPython.display import clear_output\n",
    "import matplotlib.pyplot as plt"
   ],
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\bmartin\\AppData\\Roaming\\Python\\Python313\\site-packages\\pygame\\pkgdata.py:25: UserWarning: pkg_resources is deprecated as an API. See https://setuptools.pypa.io/en/latest/pkg_resources.html. The pkg_resources package is slated for removal as early as 2025-11-30. Refrain from using this package or pin to Setuptools<81.\n",
      "  from pkg_resources import resource_stream, resource_exists\n"
     ]
    }
   ],
   "execution_count": 1
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-25T13:00:08.136317Z",
     "start_time": "2025-08-25T13:00:08.132025Z"
    }
   },
   "source": [
    "gym.register(\n",
    "        id=\"gymnasium_env/MapPodRacing-v0\",\n",
    "        entry_point=MapPodRacing,\n",
    "        max_episode_steps=1000,  # Prevent infinite episodes\n",
    ")\n",
    "\n",
    "env_name = 'gymnasium_env/MapPodRacing-v0'\n",
    "env = gym.make(env_name)"
   ],
   "outputs": [],
   "execution_count": 2
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-25T13:00:08.152160Z",
     "start_time": "2025-08-25T13:00:08.141716Z"
    }
   },
   "source": [
    "class RL(nn.Module):\n",
    "    def __init__(self, action_num=8, hidden_size=256):\n",
    "        super(RL, self).__init__()\n",
    "        self.fc1 = nn.Linear(8, hidden_size)\n",
    "        self.fc2 = nn.Linear(hidden_size, action_num)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = F.relu(self.fc1(x))\n",
    "        logits = self.fc2(x)\n",
    "        return Categorical(logits = logits)"
   ],
   "outputs": [],
   "execution_count": 3
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-25T13:00:08.162176Z",
     "start_time": "2025-08-25T13:00:08.157448Z"
    }
   },
   "source": [
    "def calc_returns(rewards, gamma = 0.99):\n",
    "    returns = []\n",
    "    delta = 0\n",
    "    for reward in rewards[::-1]:\n",
    "        #Bug fixed on this line\n",
    "        delta = reward + gamma*delta\n",
    "        returns.insert(0, delta)\n",
    "    return returns\n",
    "\n",
    "def test_agent():\n",
    "    done = False\n",
    "    total_reward = 0\n",
    "    obs, info = env.reset()\n",
    "    observation = torch.FloatTensor(obs).unsqueeze(0)\n",
    "\n",
    "    with torch.no_grad():\n",
    "        while not done:\n",
    "            dist = rl_model(observation)\n",
    "            action = dist.sample().cpu().item()\n",
    "            observation, reward, done, truncated, info = env.step(action)\n",
    "            \n",
    "            observation = torch.FloatTensor(observation).unsqueeze(0)\n",
    "            total_reward += reward\n",
    "            \n",
    "    return total_reward"
   ],
   "outputs": [],
   "execution_count": 4
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-25T13:00:09.605285Z",
     "start_time": "2025-08-25T13:00:08.169744Z"
    }
   },
   "source": [
    "rl_model = RL()\n",
    "lr = 1e-4\n",
    "optimizer = optim.SGD(rl_model.parameters(), lr=lr)"
   ],
   "outputs": [],
   "execution_count": 5
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-25T13:00:09.939718Z",
     "start_time": "2025-08-25T13:00:09.935403Z"
    }
   },
   "source": [
    "max_steps = 10000\n",
    "rollouts = 0\n",
    "step = 0\n",
    "score_logger = []"
   ],
   "outputs": [],
   "execution_count": 6
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-25T13:00:10.533376Z",
     "start_time": "2025-08-25T13:00:09.947816Z"
    }
   },
   "source": [
    "while step < max_steps:\n",
    "    obs, info = env.reset()\n",
    "    observation =  torch.FloatTensor(obs).unsqueeze(0)\n",
    "    done = False\n",
    "    rewards = []\n",
    "    log_probs = []\n",
    "    \n",
    "    while not done:\n",
    "        dist = rl_model(observation)\n",
    "        action = dist.sample()\n",
    "        log_prob = dist.log_prob(action.unsqueeze(0))\n",
    "        \n",
    "        observation, reward, done, truncated, info = env.step(action.cpu().item())\n",
    "        \n",
    "        observation = torch.FloatTensor(observation).unsqueeze(0)\n",
    "        reward = torch.FloatTensor([reward]).unsqueeze(0)\n",
    "\n",
    "        rewards.append(reward)\n",
    "        log_probs.append(log_prob)\n",
    "        step +=1\n",
    "    \n",
    "    returns = calc_returns(rewards)\n",
    "    \n",
    "    returns = torch.cat(returns, 1)\n",
    "    returns /= returns.max()\n",
    "    log_probs = torch.cat(log_probs, 1)\n",
    "    \n",
    "    action_loss = - (log_probs * returns).sum()\n",
    "    \n",
    "    optimizer.zero_grad()\n",
    "    action_loss.backward()\n",
    "    optimizer.step()\n",
    "    rollouts += 1\n",
    "    \n",
    "    if rollouts % 10 == 0:\n",
    "        new_lr = ((max_steps - step)/max_steps) * lr\n",
    "        optimizer.param_groups[0][\"lr\"] = new_lr\n",
    "        \n",
    "        score_logger.append(np.mean([test_agent() for _ in range(10)]))\n",
    "        clear_output(True)\n",
    "        plt.plot(score_logger)\n",
    "        plt.show()\n",
    "    \n",
    "env.close()"
   ],
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Expected parameter logits (Tensor of shape (1, 8)) of distribution Categorical(logits: torch.Size([1, 8])) to satisfy the constraint IndependentConstraint(Real(), 1), but found invalid values:\ntensor([[nan, nan, nan, nan, nan, nan, nan, nan]], grad_fn=<SubBackward0>)",
     "output_type": "error",
     "traceback": [
      "\u001B[31m---------------------------------------------------------------------------\u001B[39m",
      "\u001B[31mValueError\u001B[39m                                Traceback (most recent call last)",
      "\u001B[36mCell\u001B[39m\u001B[36m \u001B[39m\u001B[32mIn[7]\u001B[39m\u001B[32m, line 9\u001B[39m\n\u001B[32m      6\u001B[39m log_probs = []\n\u001B[32m      8\u001B[39m \u001B[38;5;28;01mwhile\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m done:\n\u001B[32m----> \u001B[39m\u001B[32m9\u001B[39m     dist = \u001B[43mrl_model\u001B[49m\u001B[43m(\u001B[49m\u001B[43mobservation\u001B[49m\u001B[43m)\u001B[49m\n\u001B[32m     10\u001B[39m     action = dist.sample()\n\u001B[32m     11\u001B[39m     log_prob = dist.log_prob(action.unsqueeze(\u001B[32m0\u001B[39m))\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1773\u001B[39m, in \u001B[36mModule._wrapped_call_impl\u001B[39m\u001B[34m(self, *args, **kwargs)\u001B[39m\n\u001B[32m   1771\u001B[39m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m._compiled_call_impl(*args, **kwargs)  \u001B[38;5;66;03m# type: ignore[misc]\u001B[39;00m\n\u001B[32m   1772\u001B[39m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[32m-> \u001B[39m\u001B[32m1773\u001B[39m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[43m.\u001B[49m\u001B[43m_call_impl\u001B[49m\u001B[43m(\u001B[49m\u001B[43m*\u001B[49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43m*\u001B[49m\u001B[43m*\u001B[49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1784\u001B[39m, in \u001B[36mModule._call_impl\u001B[39m\u001B[34m(self, *args, **kwargs)\u001B[39m\n\u001B[32m   1779\u001B[39m \u001B[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001B[39;00m\n\u001B[32m   1780\u001B[39m \u001B[38;5;66;03m# this function, and just call forward.\u001B[39;00m\n\u001B[32m   1781\u001B[39m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m (\u001B[38;5;28mself\u001B[39m._backward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m._backward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m._forward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m._forward_pre_hooks\n\u001B[32m   1782\u001B[39m         \u001B[38;5;129;01mor\u001B[39;00m _global_backward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_backward_hooks\n\u001B[32m   1783\u001B[39m         \u001B[38;5;129;01mor\u001B[39;00m _global_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_forward_pre_hooks):\n\u001B[32m-> \u001B[39m\u001B[32m1784\u001B[39m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mforward_call\u001B[49m\u001B[43m(\u001B[49m\u001B[43m*\u001B[49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43m*\u001B[49m\u001B[43m*\u001B[49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[32m   1786\u001B[39m result = \u001B[38;5;28;01mNone\u001B[39;00m\n\u001B[32m   1787\u001B[39m called_always_called_hooks = \u001B[38;5;28mset\u001B[39m()\n",
      "\u001B[36mCell\u001B[39m\u001B[36m \u001B[39m\u001B[32mIn[3]\u001B[39m\u001B[32m, line 10\u001B[39m, in \u001B[36mRL.forward\u001B[39m\u001B[34m(self, x)\u001B[39m\n\u001B[32m      8\u001B[39m x = F.relu(\u001B[38;5;28mself\u001B[39m.fc1(x))\n\u001B[32m      9\u001B[39m logits = \u001B[38;5;28mself\u001B[39m.fc2(x)\n\u001B[32m---> \u001B[39m\u001B[32m10\u001B[39m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mCategorical\u001B[49m\u001B[43m(\u001B[49m\u001B[43mlogits\u001B[49m\u001B[43m \u001B[49m\u001B[43m=\u001B[49m\u001B[43m \u001B[49m\u001B[43mlogits\u001B[49m\u001B[43m)\u001B[49m\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\torch\\distributions\\categorical.py:81\u001B[39m, in \u001B[36mCategorical.__init__\u001B[39m\u001B[34m(self, probs, logits, validate_args)\u001B[39m\n\u001B[32m     77\u001B[39m \u001B[38;5;28mself\u001B[39m._num_events = \u001B[38;5;28mself\u001B[39m._param.size()[-\u001B[32m1\u001B[39m]\n\u001B[32m     78\u001B[39m batch_shape = (\n\u001B[32m     79\u001B[39m     \u001B[38;5;28mself\u001B[39m._param.size()[:-\u001B[32m1\u001B[39m] \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m._param.ndimension() > \u001B[32m1\u001B[39m \u001B[38;5;28;01melse\u001B[39;00m torch.Size()\n\u001B[32m     80\u001B[39m )\n\u001B[32m---> \u001B[39m\u001B[32m81\u001B[39m \u001B[38;5;28;43msuper\u001B[39;49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\u001B[43m.\u001B[49m\u001B[34;43m__init__\u001B[39;49m\u001B[43m(\u001B[49m\u001B[43mbatch_shape\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mvalidate_args\u001B[49m\u001B[43m=\u001B[49m\u001B[43mvalidate_args\u001B[49m\u001B[43m)\u001B[49m\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\torch\\distributions\\distribution.py:77\u001B[39m, in \u001B[36mDistribution.__init__\u001B[39m\u001B[34m(self, batch_shape, event_shape, validate_args)\u001B[39m\n\u001B[32m     75\u001B[39m         valid = constraint.check(value)\n\u001B[32m     76\u001B[39m         \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m torch._is_all_true(valid):\n\u001B[32m---> \u001B[39m\u001B[32m77\u001B[39m             \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mValueError\u001B[39;00m(\n\u001B[32m     78\u001B[39m                 \u001B[33mf\u001B[39m\u001B[33m\"\u001B[39m\u001B[33mExpected parameter \u001B[39m\u001B[38;5;132;01m{\u001B[39;00mparam\u001B[38;5;132;01m}\u001B[39;00m\u001B[33m \u001B[39m\u001B[33m\"\u001B[39m\n\u001B[32m     79\u001B[39m                 \u001B[33mf\u001B[39m\u001B[33m\"\u001B[39m\u001B[33m(\u001B[39m\u001B[38;5;132;01m{\u001B[39;00m\u001B[38;5;28mtype\u001B[39m(value).\u001B[34m__name__\u001B[39m\u001B[38;5;132;01m}\u001B[39;00m\u001B[33m of shape \u001B[39m\u001B[38;5;132;01m{\u001B[39;00m\u001B[38;5;28mtuple\u001B[39m(value.shape)\u001B[38;5;132;01m}\u001B[39;00m\u001B[33m) \u001B[39m\u001B[33m\"\u001B[39m\n\u001B[32m     80\u001B[39m                 \u001B[33mf\u001B[39m\u001B[33m\"\u001B[39m\u001B[33mof distribution \u001B[39m\u001B[38;5;132;01m{\u001B[39;00m\u001B[38;5;28mrepr\u001B[39m(\u001B[38;5;28mself\u001B[39m)\u001B[38;5;132;01m}\u001B[39;00m\u001B[33m \u001B[39m\u001B[33m\"\u001B[39m\n\u001B[32m     81\u001B[39m                 \u001B[33mf\u001B[39m\u001B[33m\"\u001B[39m\u001B[33mto satisfy the constraint \u001B[39m\u001B[38;5;132;01m{\u001B[39;00m\u001B[38;5;28mrepr\u001B[39m(constraint)\u001B[38;5;132;01m}\u001B[39;00m\u001B[33m, \u001B[39m\u001B[33m\"\u001B[39m\n\u001B[32m     82\u001B[39m                 \u001B[33mf\u001B[39m\u001B[33m\"\u001B[39m\u001B[33mbut found invalid values:\u001B[39m\u001B[38;5;130;01m\\n\u001B[39;00m\u001B[38;5;132;01m{\u001B[39;00mvalue\u001B[38;5;132;01m}\u001B[39;00m\u001B[33m\"\u001B[39m\n\u001B[32m     83\u001B[39m             )\n\u001B[32m     84\u001B[39m \u001B[38;5;28msuper\u001B[39m().\u001B[34m__init__\u001B[39m()\n",
      "\u001B[31mValueError\u001B[39m: Expected parameter logits (Tensor of shape (1, 8)) of distribution Categorical(logits: torch.Size([1, 8])) to satisfy the constraint IndependentConstraint(Real(), 1), but found invalid values:\ntensor([[nan, nan, nan, nan, nan, nan, nan, nan]], grad_fn=<SubBackward0>)"
     ]
    }
   ],
   "execution_count": 7
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "plt.plot(score_logger)"
   ],
   "outputs": [],
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
